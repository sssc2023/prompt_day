__import__('pysqlite3')
import sys

sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import streamlit as st
import tempfile
import os
from PIL import Image
import time

# ì œëª©
st.title("SightnSpeak")
st.title("ê°€ë³´ìê³ ")
st.write("---")

# ë°© ì´ë¯¸ì§€
cyworld_img = Image.open('picture/livingroom.jpg')
# ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
cyworld_img = cyworld_img.resize((650, int(650 * (cyworld_img.height / cyworld_img.width))))
st.image(cyworld_img, width=650)
st.write("---")

db_ac = Chroma(persist_directory='./ac', embedding_function=OpenAIEmbeddings())
db_tv = Chroma(persist_directory='./tv', embedding_function=OpenAIEmbeddings())
db_hm = Chroma(persist_directory='./hm', embedding_function=OpenAIEmbeddings())
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

def wrap_text(text, line_length=18):  # ì±—ë´‡ ê¸€ììˆ˜ ì¡°ì ˆ..
    lines = []
    for i in range(0, len(text), line_length):
        lines.append(text[i:i + line_length])
    return "\n".join(lines)


# ì´ˆê¸° ì„¸ì…˜ ìƒíƒœ ì„¤ì •
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = {'AC': [], 'TV': [], 'HM': []}
if 'selected_device' not in st.session_state:
    st.session_state.selected_device = None

    # Choice
st.subheader("ì„ íƒí•  ê¸°ê¸°ë¥¼ ë°”ë¼ë³´ì„¸ìš”!")
col1, col2, col3 = st.columns(3)
with col1:
    st.image("picture/person_AC.jpg", width=100)
    st.markdown("â„ï¸ì—ì–´ì»¨ì„ ë°”ë¼ë³¸ë‹¤", unsafe_allow_html=True)
    if st.button("ì—ì–´ì»¨ ì„ íƒ"):
        st.success("ì—ì–´ì»¨ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.selected_device = 'AC'

with col2:
    st.image("picture/person_TV.jpg", width=100)
    st.markdown("ğŸ“ºTVë¥¼ ë°”ë¼ë³¸ë‹¤", unsafe_allow_html=True)
    if st.button("TV ì„ íƒ"):
        st.success("TVê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.selected_device = 'TV'

with col3:
    st.image("picture/person_HM.jpg", width=100)
    st.markdown("ğŸ’§ê°€ìŠµê¸°ë¥¼ ë°”ë¼ë³¸ë‹¤", unsafe_allow_html=True)
    if st.button("ê°€ìŠµê¸° ì„ íƒ"):
        st.success("ê°€ìŠµê¸°ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.selected_device = 'HM'

st.write("---")

# ì§ˆë¬¸í•˜ê¸° ì°½ì´ ë‚˜íƒ€ë‚˜ëŠ” ì¡°ê±´ì„ ì¶”ê°€
# Air Conditioner
if st.session_state.selected_device == 'AC':
    st.subheader("â„ï¸ì—ì–´ì»¨ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    ac_img = Image.open('picture/air-conditioner.png')
    ac_img = ac_img.resize((100, 100))
    st.image(ac_img)
    ac_question = st.text_input('ì•ˆë…•í•˜ì„¸ìš”, ì „ ì—ì–´ì»¨ì´ì—ìš”. ìŠìŠ~', key='ac')
    st.write("---")
    with st.spinner('Wait for it...'):
        qa_chain_ac = RetrievalQA.from_chain_type(llm, retriever=db_ac.as_retriever())
        if ac_question != "":
            result = qa_chain_ac({"query": ac_question + 'ëŒ€ë‹µì„ ë‹¤ ë§ˆì¹˜ê³  ìŠìŠ!ì´ë¼ê³  ë§í•´ì¤˜'})
            st.session_state.chat_history['AC'].append({"question": ac_question, "answer": result["result"]})

    # ì±— ê¸°ë¡ ì¶œë ¥
    for chat in st.session_state.chat_history['AC']:
        st.text(f"ğŸ¤” {chat['question']}")
        st.text(f"ğŸ˜Š {chat['answer']}")
        st.write("---")

# TV
elif st.session_state.selected_device == 'TV':
    st.subheader("ğŸ“ºTVì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    tv_img = Image.open('picture/television.png')
    tv_img = tv_img.resize((100, 100))
    st.image(tv_img)
    tv_question = st.text_input('í…”ë ˆë¹„ì „ì—ê²Œ ë¬¼ì–´ë´í‹°ë¹„~')
    st.write("---")
    with st.spinner('Wait for it...'):
        qa_chain_tv = RetrievalQA.from_chain_type(llm, retriever=db_tv.as_retriever())
        if tv_question != "":
            result = qa_chain_tv({"query": tv_question + 'ëŒ€ë‹µì„ ë‹¤ ë§ˆì¹˜ê³  ë–¼ë ˆë¹„!ë¼ê³  ë§í•´ì¤˜'})
            st.session_state.chat_history['TV'].append({"question": tv_question, "answer": result["result"]})

    # ì±— ê¸°ë¡ ì¶œë ¥
    for chat in st.session_state.chat_history['TV']:
        st.text(f"ğŸ¤” {chat['question']}")
        st.text(f"ğŸ˜Š {chat['answer']}")
        st.write("---")

# Humidifier
elif st.session_state.selected_device == 'HM':
    st.subheader("ğŸ’§ê°€ìŠµê¸°ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    hm_img = Image.open('picture/humidifier.png')
    hm_img = hm_img.resize((100, 100))
    st.image(hm_img)
    hm_question = st.text_input('ì•ˆë…•? ë‚´ê°€ ì•„ëŠ” ëª¨ë“  ê±¸ ì´‰ì´‰í•˜ê²Œ ì•Œë ¤ì¤„ê²Œ!', key='hm')
    st.write("---")
    with st.spinner('Wait for it...'):
        qa_chain_hm = RetrievalQA.from_chain_type(llm, retriever=db_hm.as_retriever())
        if hm_question != "":
            result = qa_chain_hm({"query": hm_question + 'ëŒ€ë‹µì„ ë‹¤ ë§ˆì¹˜ê³  ì¶•ì¶•!ì´ë¼ê³  ë§í•´ì¤˜'})
            st.session_state.chat_history['HM'].append({"question": hm_question, "answer": result["result"]})

    # ì±— ê¸°ë¡ ì¶œë ¥
    for chat in st.session_state.chat_history['HM']:
        st.text(f"ğŸ¤” {chat['question']}")
        st.text(f"ğŸ˜Š {chat['answer']}")
        st.write("---")
